{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nandyc/langchain-rag-basics/blob/main/langchain_rag_QnA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saMdkS7iYMRf",
        "outputId": "073d8d7f-0aa0-487b-b629-032801cf4b8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'langchain-rag-basics'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 9 (delta 2), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (9/9), 59.53 KiB | 539.00 KiB/s, done.\n",
            "Resolving deltas: 100% (2/2), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/nandyc/langchain-rag-basics.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd langchain-rag-basics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtR0EjOFYhbE",
        "outputId": "e47933e0-bb07-4c8c-c585-b927669e71ec"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/langchain-rag-basics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "### Install required modules and set the envvar for Gemini API Key\n",
        "!pip install pypdf2\n",
        "!pip install chromadb\n",
        "!pip install google.generativeai\n",
        "!pip install langchain-google-genai\n",
        "!pip install langchain\n",
        "!pip install langchain_community"
      ],
      "metadata": {
        "id": "UgS91MLAYxQf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Python modules\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.vectorstores import Chroma\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "sBf6dWoJY0SM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#export GOOGLE_API_KEY=\"YOUR_GOOGLE_API_KEY\"\n",
        "GOOGLE_API_KEY =userdata.get('GEMINI_APIKEY')"
      ],
      "metadata": {
        "id": "zRylZlUgZd-0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the models\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key = GOOGLE_API_KEY)\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key = GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "RYXsCdxRZQju"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the PDF and create chunks\n",
        "loader = PyPDFLoader(\"handbook.pdf\")\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator=\".\",\n",
        "    chunk_size=250,\n",
        "    chunk_overlap=50,\n",
        "    length_function=len,\n",
        "    is_separator_regex=False,\n",
        ")"
      ],
      "metadata": {
        "id": "oEddLqR3CIeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pages = loader.load_and_split(text_splitter)"
      ],
      "metadata": {
        "id": "qPqlEinFlS7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Turn the chunks into embeddings and store them in Chroma\n",
        "vectordb=Chroma.from_documents(pages,embeddings)"
      ],
      "metadata": {
        "id": "TePyfs6LlVQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Configure Chroma as a retriever with top_k=5\n",
        "retriever = vectordb.as_retriever(search_kwargs={\"k\": 5})"
      ],
      "metadata": {
        "id": "RXzQKgmylWbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the retrieval chain\n",
        "template = \"\"\"\n",
        "You are a helpful AI assistant.\n",
        "Answer based on the context provided.\n",
        "context: {context}\n",
        "input: {input}\n",
        "answer:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "nws8IbnAlYRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate.from_template(template)\n",
        "combine_docs_chain = create_stuff_documents_chain(llm, prompt)\n",
        "retrieval_chain = create_retrieval_chain(retriever, combine_docs_chain)"
      ],
      "metadata": {
        "id": "TZwZ14lMlZu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Invoke the retrieval chain\n",
        "response=retrieval_chain.invoke({\"input\":\"How do I apply for personal leave?\"})"
      ],
      "metadata": {
        "id": "rxx9_ToDlbD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print the answer to the question\n",
        "print(response[\"answer\"])"
      ],
      "metadata": {
        "id": "oZx5SKySlcOU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}